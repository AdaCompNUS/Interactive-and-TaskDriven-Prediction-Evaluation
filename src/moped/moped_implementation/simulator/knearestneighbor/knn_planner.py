from simulator.base_simulator import Simulator
from utils.social_features_utils import SocialFeaturesUtils
from utils.social_features_vectorize import SocialFeaturesUtilsVectorize
from utils import baseline_utils
from utils.map_features_utils import MapFeaturesUtils
from utils.baseline_config import RAW_DATA_FORMAT, FEATURE_FORMAT
import numpy as np
import time
import multiprocessing
from pathlib import Path
ROOT = Path(__file__).resolve().parent
import pickle
from typing import Dict, Any, Tuple, List
from mmcv import Config
import pandas as pd
import math
from shapely.geometry import Point, Polygon, LineString, LinearRing
from shapely.affinity import affine_transform, rotate
import copy
class KNNPlanner(Simulator):
    WEIGHT_PATH_DEFAULT = f'{ROOT}/knn/summit_knn_grid_search.pkl' # must be default or nomap-nosocial
    WEIGHT_PATH_SOCIAL = f'{ROOT}/knn_social/summit_knn_grid_search.pkl' # must be default or nomap-nosocial
    # this file is generated by train.py. Just run python train.py with any configs, then
    # it will be generated. The train file contains map/social features of train dataset.
    TRAIN_FEATURES_PKL = f'{ROOT}/train_features.pkl'

    def __init__(self, use_social):
        self.social_features_utils_vectorize_instance = SocialFeaturesUtilsVectorize()
        self.normalize = True # Support True/False. From inputs to process
        self.use_delta = True # Support True/False. From inputs to process
        self.use_map = False # Do not support True
        self.use_social = use_social # Support True and False. For building inputs
        self.WEIGHT = KNNPlanner.WEIGHT_PATH_SOCIAL if self.use_social else KNNPlanner.WEIGHT_PATH_DEFAULT
        self.train_features_df = self.preprocess_train_output()
        self.model = pd.read_pickle(self.WEIGHT)
        self.n_neigh = 1

    def run(self, trajectories: np.ndarray):
        pass

    def array2dict(self, trajectories: np.ndarray):
        pass

    def dict2run(self, data_dict: dict):
        pass

    def preprocess_train_output(self):
        """
        Preprocess the train output to be used for training the KNN model
        Returns:
            train_output (numpy array): shape (num_tracks x 30 X 2)

        """
        train_features_df = pd.read_pickle(KNNPlanner.TRAIN_FEATURES_PKL)
        # Shape [num_agents, obs_len+pred_len, 2]
        train_xy = np.stack(train_features_df["FEATURES"].values)[:, :, [FEATURE_FORMAT["X"], FEATURE_FORMAT["Y"]]]

        if self.normalize:
            _, _, normalize_traj_arr = self.normalize_trajectories(train_xy, obs_len=20)
        else:
            normalize_traj_arr = train_xy

        if self.use_delta:
            _ = self.get_relative_distance(normalize_traj_arr, "train", 20, 30)

        return normalize_traj_arr[:, 20:, :] # only return the last 30 frames


    def get_relative_distance(self, data: np.ndarray, mode: str, obs_len: int, pred_len: int) -> np.ndarray:
        """Convert absolute distance to relative distance in place and return the reference (first value).
        Args:
            data (numpy array): Data array of shape (num_tracks x seq_len X num_features). Distances are always the first 2 features
            mode: train/val/test
            args: Arguments passed to the baseline code
        Returns:
            reference (numpy array): First value of the sequence of data with shape (num_tracks x 2). For map based baselines, it will be first n-t distance of the trajectory.
        """
        reference = copy.deepcopy(data[:, 0, :2])

        if mode == "test":
            traj_len = obs_len
        else:
            traj_len = obs_len + pred_len

        for i in range(traj_len - 1, 0, -1):
            data[:, i, :2] = data[:, i, :2] - data[:, i - 1, :2]
        data[:, 0, :] = 0
        return reference

    def normalize_trajectories(self, trajectories: np.ndarray, obs_len: int):
        """

        Args:
            trajectories: shape [num_agents, obs_len, 2]

        Returns:
            translation [num_agents]
            , rotations [num_agents, 6]
            , and normalized trajectories [num_agents, obs_len, 2]

        """
        translation = []
        rotation = []

        normalized_traj = []
        x_coord_seq = trajectories[:, :, 0]
        y_coord_seq = trajectories[:, :, 1]

        # Normalize each trajectory
        for i in range(x_coord_seq.shape[0]):
            xy_seq = np.stack((x_coord_seq[i], y_coord_seq[i]), axis=-1)

            start = xy_seq[0]

            # First apply translation
            m = [1, 0, 0, 1, -start[0], -start[1]]
            ls = LineString(xy_seq)

            # Now apply rotation, taking care of edge cases
            ls_offset = affine_transform(ls, m)
            end = ls_offset.coords[obs_len - 1]
            if end[0] == 0 and end[1] == 0:
                angle = 0.0
            elif end[0] == 0:
                angle = -90.0 if end[1] > 0 else 90.0
            elif end[1] == 0:
                angle = 0.0 if end[0] > 0 else 180.0
            else:
                angle = math.degrees(math.atan(end[1] / end[0]))
                if (end[0] > 0 and end[1] > 0) or (end[0] > 0 and end[1] < 0):
                    angle = -angle
                else:
                    angle = 180.0 - angle

            # Rotate the trajetory
            ls_rotate = rotate(ls_offset, angle, origin=(0, 0)).coords[:]

            # Normalized trajectory
            norm_xy = np.array(ls_rotate)

            # Update the containers
            normalized_traj.append(norm_xy)
            translation.append(m)
            rotation.append(angle)

        # Update the dataframe and return the normalized trajectory
        normalize_traj_arr = np.stack(normalized_traj)

        return translation, rotation, normalize_traj_arr
    def preprocess(self, input_features: np.ndarray):
        """
            Processing the input features.
            "social": ["X", "Y", "MIN_DISTANCE_FRONT", "MIN_DISTANCE_BACK", "NUM_NEIGHBORS"]
            "none": ["X", "Y"]

            Output:
            "social": ["X", "Y"]
            "none": ["X", "Y"]

            Args:
                input_features: shape [num_agents, obs_len, 2]

            Returns:
                translation,
                rotation,
                reference,
                input_features: shape [num_agents, obs_len, 5]
        """
        # Step 1. Build agent vector
        # Output shape [num_agents, obs_len, 5]
        a = time.time()
        agent_vec = self.build_all_agents_vec(input_features)

        b = time.time()
        # Step 2. Normalize if normalize = True
        if self.normalize:
            xy_trajectories = agent_vec[:, :, 0:2] # the first 2 columns are x, y
            translation, rotation, normalize_traj_arr = self.normalize_trajectories(xy_trajectories, obs_len=20)
            # Add back the social features
            normalize_traj_arr = np.concatenate((normalize_traj_arr, agent_vec[:, :, 2:]), axis=-1)
        else:
            translation, rotation, normalize_traj_arr = None, None, agent_vec

        # Step 2.a. Dependings on if self.social, filter the columns
        if not self.use_social:
            normalize_traj_arr = normalize_traj_arr[:, :, 0:2]

        c = time.time()
        # Step 3. Get relative distance. xy must be in first 2 columns
        if self.use_delta:
            reference = self.get_relative_distance(normalize_traj_arr, mode="test", obs_len=20, pred_len=30)
        else:
            reference = None

        d = time.time()
        #print("Time for each step: ", b-a, c-b, d-c, d-a)

        return translation, rotation, reference, normalize_traj_arr

    def build_all_agents_vec(self, trajectories: np.ndarray):
        """

        Args:
            trajectories: shape [num_agents, obs_len, 2]

        Returns:
            merged_vec: shape [num_agents, obs_len, 5]
        """

        if self.use_social:
            social_features = []
            social_index = self.social_features_utils_vectorize_instance.filter_tracks(trajectories, 20, {"X": 0, "Y": 1})
            for agent_index in range(trajectories.shape[0]):
                social_index_i = [item for item in social_index if item != agent_index]
                social_feature = self.social_features_utils_vectorize_instance.compute_social_features_vec(
                    trajectories, social_index_i, agent_index, 20
                )
                social_features.append(social_feature)
            ## shape [num_agents, obs_len, 3], where 3 is [min_dist_from, min_dist_back, num_neighbors]
            social_features = np.array(social_features)
            # shape [num_agents, obs_len, 5], where 5 is [x, y, min_dist_from, min_dist_back, num_neighbors]
            merged_features = np.concatenate([trajectories, social_features], axis=2)
        else:
            # shape [num_agents, obs_len, 5], where 5 is [x, y, None, None, None]
            merged_features = np.full((trajectories.shape[0], trajectories.shape[1], 5), None)
            merged_features[:, :, 0:2] = trajectories

        return merged_features

    def normalized_to_map_coordinates(self, coords: np.ndarray,
                                      translation: List[List[float]],
                                      rotation: List[float]) -> np.ndarray:
        """Denormalize trajectory to bring it back to map frame.
        Args:
            coords (numpy array): Array of shape (num_tracks x seq_len x 2) containing normalized coordinates
            translation (list): Translation matrix used in normalizing trajectories
            rotation (list): Rotation angle used in normalizing trajectories
        Returns:
            _ (numpy array: Array of shape (num_tracks x seq_len x 2) containing coordinates in map frame
        """
        abs_coords = []
        for i in range(coords.shape[0]):
            ls = LineString(coords[i])

            # Rotate
            ls_rotate = rotate(ls, -rotation[i], origin=(0, 0))

            # Translate
            M_inv = [1, 0, 0, 1, -translation[i][4], -translation[i][5]]

            ls_offset = affine_transform(ls_rotate, M_inv).coords[:]
            abs_coords.append(ls_offset)

        return np.array(abs_coords)

    def predict_default(self, trajectory: np.ndarray, pred_len: int, obs_len: int):
        """

        Args:
            trajectory:
            pred_len:
            obs_len: must be 20

        Returns:

        """
        # Step 1. Build agent vector
        # shape of inputs: [num_agents, obs_len, 5]
        a = time.time()
        translation, rotation, reference, normalize_traj_arr = self.preprocess(trajectory)
        normalize_traj_arr = normalize_traj_arr.astype(float)
        b = time.time()
        # Step 3. Predict
        test_references = reference
        test_translation = translation
        test_rotation = rotation

        test_num_tracks = normalize_traj_arr.shape[0]
        num_features = normalize_traj_arr.shape[2]
        test_input = normalize_traj_arr.reshape(
            (test_num_tracks, obs_len * num_features), order="F")

        forecasted_trajectories = {}

        # Preprocess and get neighbors
        pipeline_steps = self.model.best_estimator_.named_steps.keys()
        preprocessed_test_input = np.copy(test_input)
        for step in pipeline_steps:
            curr_step = self.model.best_estimator_.named_steps[step]

            # Get neighbors
            if step == "regressor":
                neigh_idx = curr_step.kneighbors(
                    preprocessed_test_input,
                    return_distance=False,
                    n_neighbors=self.n_neigh,
                )

            # Preprocess
            else:
                if curr_step is not None:
                    preprocessed_test_input = curr_step.transform(
                        preprocessed_test_input)

        args = Config({
            "use_delta": self.use_delta,
            "normalize": self.normalize,
            "use_map": self.use_map,
            "joblib_batch_size": 1
        })

        # Predict for each trajectory
        c = time.time()
        # for i in range(test_num_tracks):
        #
        #     curr_test_input = np.repeat(test_input[i],
        #                                 repeats=self.n_neigh,
        #                                 axis=0)
        #     neigh_output = self.train_features_df[neigh_idx][
        #                    i, :, :pred_len, :]  # num_neigh x curr_pred_len x 2
        #
        #     abs_helpers = {}
        #     if self.use_delta:
        #         abs_helpers["REFERENCE"] = np.array(
        #             [test_references[i] for _ in range(self.n_neigh)])
        #     if self.normalize:
        #         abs_helpers["TRANSLATION"] = np.array(
        #             [test_translation[i] for _ in range(self.n_neigh)])
        #         abs_helpers["ROTATION"] = np.array(
        #             [test_rotation[i] for _ in range(self.n_neigh)])
        #
        #     # Convert trajectory to map frame
        #     abs_input, abs_output = baseline_utils.get_abs_traj(
        #         curr_test_input.copy().reshape(
        #             (-1, obs_len, num_features), order="F"),
        #         neigh_output.copy(),
        #         args,
        #         helpers=abs_helpers,
        #     )
        #     forecasted_trajectories[i] = abs_output

        # Vectorize only with n_neigh = 1
        e = time.time()
        abs_helpers = {}
        if self.use_delta:
            abs_helpers["REFERENCE"] = test_references
        if self.normalize:
            abs_helpers["TRANSLATION"] = np.array(test_translation)
            abs_helpers["ROTATION"] = np.array(test_rotation)

        # Convert trajectory to map frame

        abs_input, abs_output = baseline_utils.get_abs_traj(
            test_input.copy().reshape(
                (-1, obs_len, num_features), order="F"),
            self.train_features_df[neigh_idx][:, 0, :, :].copy(),
            args,
            helpers=abs_helpers,
        )

        f = time.time()

        #assert np.isclose(np.concatenate(list(forecasted_trajectories.values()), axis=0), abs_output).all()
        d = time.time()
        #print("time for each steps in predict_nomap_nosocial: ", b - a, d - b, d-a)
        #print("time for each methodl: ", e-c, f-e)

        # The abs_output has shape [num_agents, pred_len, 2], thus slicing first pred
        return abs_output[:, :pred_len, :]